{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb \n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 10000\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "batch_size=128\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test) \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "  def __init__(self, return_sequences=True):\n",
    "      self.return_sequences = return_sequences\n",
    "      super(Attention,self).__init__()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "      self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                              initializer=\"normal\")\n",
    "      self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                              initializer=\"zeros\")\n",
    "\n",
    "      super(Attention,self).build(input_shape)\n",
    "  def call(self, x):\n",
    "      e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "      a = K.softmax(e, axis=1)\n",
    "      output = x*a\n",
    "      if self.return_sequences:\n",
    "\n",
    "          return output\n",
    "      return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "attention (Attention)        (None, 200, 128)          328       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,399,785\n",
      "Trainable params: 1,399,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Attention(return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "157/157 [==============================] - 31s 108ms/step - loss: 0.6770 - accuracy: 0.5627 - val_loss: 0.5941 - val_accuracy: 0.7296\n",
      "Epoch 2/12\n",
      "157/157 [==============================] - 14s 87ms/step - loss: 0.4541 - accuracy: 0.7989 - val_loss: 0.3742 - val_accuracy: 0.8324\n",
      "Epoch 3/12\n",
      "157/157 [==============================] - 13s 80ms/step - loss: 0.2951 - accuracy: 0.8875 - val_loss: 0.3489 - val_accuracy: 0.8468\n",
      "Epoch 4/12\n",
      "157/157 [==============================] - 13s 81ms/step - loss: 0.2020 - accuracy: 0.9298 - val_loss: 0.3471 - val_accuracy: 0.8690\n",
      "Epoch 5/12\n",
      "157/157 [==============================] - 14s 91ms/step - loss: 0.1448 - accuracy: 0.9543 - val_loss: 0.3821 - val_accuracy: 0.8726\n",
      "Epoch 6/12\n",
      "157/157 [==============================] - 14s 92ms/step - loss: 0.1059 - accuracy: 0.9679 - val_loss: 0.4565 - val_accuracy: 0.8610\n",
      "Epoch 7/12\n",
      "157/157 [==============================] - 14s 92ms/step - loss: 0.0791 - accuracy: 0.9776 - val_loss: 0.5078 - val_accuracy: 0.8598\n",
      "Epoch 8/12\n",
      "157/157 [==============================] - 14s 92ms/step - loss: 0.0617 - accuracy: 0.9833 - val_loss: 0.4583 - val_accuracy: 0.8480\n",
      "Epoch 9/12\n",
      "157/157 [==============================] - 14s 91ms/step - loss: 0.0546 - accuracy: 0.9853 - val_loss: 0.5644 - val_accuracy: 0.8528\n",
      "Epoch 10/12\n",
      "157/157 [==============================] - 15s 96ms/step - loss: 0.0466 - accuracy: 0.9873 - val_loss: 0.5910 - val_accuracy: 0.8524\n",
      "Epoch 11/12\n",
      "157/157 [==============================] - 15s 94ms/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.6253 - val_accuracy: 0.8528\n",
      "Epoch 12/12\n",
      "157/157 [==============================] - 15s 96ms/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.6524 - val_accuracy: 0.8554\n"
     ]
    }
   ],
   "source": [
    "history3d=model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=12,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6891 - accuracy: 0.8475\n",
      "Test loss and accuracy:  [0.6891041994094849, 0.8475199937820435]\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss and accuracy: \",cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 test results:\n",
      "Prediction: [0.04758357] Actual: 0\n",
      "Prediction: [0.9995814] Actual: 1\n",
      "Prediction: [0.12353067] Actual: 1\n",
      "Prediction: [0.36380428] Actual: 0\n",
      "Prediction: [0.9995702] Actual: 1\n",
      "Prediction: [0.99945325] Actual: 1\n",
      "Prediction: [0.99951017] Actual: 1\n",
      "Prediction: [0.00077298] Actual: 0\n",
      "Prediction: [0.99961734] Actual: 0\n",
      "Prediction: [0.9996784] Actual: 1\n"
     ]
    }
   ],
   "source": [
    "y_preds=model.predict(x_test)\n",
    "print(\"First 10 test results:\")\n",
    "for i in range(10):\n",
    "    print(\"Prediction: {} Actual: {}\".format(y_preds[i],y_test[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e12ac12a945f382e98440b0c94bbcb50fa5b9249500f0365ebc1c5d407b008b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
